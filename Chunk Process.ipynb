{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nama:** Ghassani Nurbaningtyas\n",
    "\n",
    "**Role:** Data Engineer\n",
    "\n",
    "**Project Explanation:** In this project, the task was to process a tax-related regulation document, specifically Konsolidasi.pdf, by applying text chunking/splitting techniques. The document needed to be segmented into meaningful sections based on the following criteria: content, chapter (Bab), article (Pasal), paragraph (Ayat), whether the section contains an explanation or not, then export to CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extract PDF to text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Extract text from Konsolidasi.pdf\n",
    "pdf_path = \"./Konsolidasi.pdf\" \n",
    "document_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Show Result Text\n",
    "# print(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Teks': '(1) Yang menjadi Subjek Pajak adalah : ', 'Bab': 'II', 'Pasal': '2', 'Ayat': '1', 'Poin': None, 'Penjelasan': 'Bukan'}\n"
     ]
    }
   ],
   "source": [
    "# Function to chunk the text\n",
    "def chunk_document(text):\n",
    "    chunks = []\n",
    "    bab = pasal = ayat = poin = None\n",
    "    current_chunk = {\"Teks\": \"\", \"Bab\": None, \"Pasal\": None, \"Ayat\": None, \"Poin\": None, \"Penjelasan\": \"Bukan\"}\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Check if the line contains \"Penjelasan\" to switch to explanation mode\n",
    "        if line.startswith(\"Penjelasan\"):\n",
    "            if current_chunk[\"Teks\"]:\n",
    "                chunks.append(current_chunk)\n",
    "            current_chunk = {\"Teks\": \"\", \"Bab\": bab, \"Pasal\": pasal, \"Ayat\": ayat, \"Poin\": poin, \"Penjelasan\": \"Ya\"}\n",
    "            \n",
    "        # Check for \"BAB\" to set the Bab value\n",
    "        elif line.startswith(\"BAB\"):\n",
    "            if current_chunk[\"Teks\"]:\n",
    "                chunks.append(current_chunk)\n",
    "            bab_match = re.search(r\"BAB\\s+([IVXLC]+)\", line)\n",
    "            if bab_match:\n",
    "                bab = bab_match.group(1)\n",
    "            current_chunk = {\"Teks\": \"\", \"Bab\": bab, \"Pasal\": pasal, \"Ayat\": ayat, \"Poin\": poin, \"Penjelasan\": \"Bukan\"}\n",
    "        \n",
    "        # Check for \"Pasal\" at the start of the line to set the Pasal value\n",
    "        elif line.startswith(\"Pasal\"):\n",
    "            if current_chunk[\"Teks\"]:\n",
    "                chunks.append(current_chunk)\n",
    "            pasal_match = re.search(r\"Pasal\\s+(\\d+)\", line)\n",
    "            if pasal_match:\n",
    "                pasal = pasal_match.group(1)\n",
    "            current_chunk = {\"Teks\": \"\", \"Bab\": bab, \"Pasal\": pasal, \"Ayat\": ayat, \"Poin\": poin, \"Penjelasan\": \"Bukan\"}\n",
    "\n",
    "        # Check for \"Ayat\" (e.g., (1)) and set Ayat value\n",
    "        elif re.match(r\"\\(\\d+[a-z]?\\)\", line):\n",
    "            if current_chunk[\"Teks\"]:\n",
    "                chunks.append(current_chunk)\n",
    "            ayat_match = re.search(r\"\\((\\d+[a-z]?)\\)\", line)\n",
    "            if ayat_match:\n",
    "                ayat = ayat_match.group(1)\n",
    "                poin = None  # Reset poin\n",
    "            current_chunk = {\"Teks\": \"\", \"Bab\": bab, \"Pasal\": pasal, \"Ayat\": ayat, \"Poin\": poin, \"Penjelasan\": \"Bukan\"}\n",
    "            current_chunk[\"Teks\"] += line + \" \"\n",
    "        \n",
    "        # Check for \"Poin\" and set Poin value (e.g., a. or Huruf a)\n",
    "        elif re.match(r\"^[a-z]\\.|Huruf\\s*[a-z]\", line):\n",
    "            if current_chunk[\"Teks\"]:\n",
    "                chunks.append(current_chunk)\n",
    "            poin_match = re.search(r\"([a-z])\", line)\n",
    "            if poin_match:\n",
    "                poin = poin_match.group(1)  # Capture only the letter\n",
    "            current_chunk = {\"Teks\": \"\", \"Bab\": bab, \"Pasal\": pasal, \"Ayat\": ayat, \"Poin\": poin, \"Penjelasan\": \"Bukan\"}\n",
    "            current_chunk[\"Teks\"] += line + \" \"\n",
    "\n",
    "        # Otherwise, append the line to the current chunk's text\n",
    "        else:\n",
    "            current_chunk[\"Teks\"] += line + \" \"\n",
    "\n",
    "    # Append the last chunk\n",
    "    if current_chunk[\"Teks\"]:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking function to the extracted text\n",
    "chunks = chunk_document(document_text)\n",
    "\n",
    "# Check chunking result\n",
    "print(chunks[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>Bab</th>\n",
       "      <th>Pasal</th>\n",
       "      <th>Ayat</th>\n",
       "      <th>Poin</th>\n",
       "      <th>Penjelasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TaxBase 6.0 Document - Page : 1SUSUNAN DALAM S...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KETENTUAN UMUM</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pajak Penghasilan dikenakan terhadap Subjek Pa...</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undang-Undang ini mengatur pengenaan Pajak Pen...</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJEK PAJAK</td>\n",
       "      <td>II</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bukan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teks   Bab Pasal  Ayat  Poin  \\\n",
       "0  TaxBase 6.0 Document - Page : 1SUSUNAN DALAM S...  None  None  None  None   \n",
       "1                                    KETENTUAN UMUM      I  None  None  None   \n",
       "2  Pajak Penghasilan dikenakan terhadap Subjek Pa...     I     1  None  None   \n",
       "3  Undang-Undang ini mengatur pengenaan Pajak Pen...     I     1  None  None   \n",
       "4                                      SUBJEK PAJAK     II     1  None  None   \n",
       "\n",
       "  Penjelasan  \n",
       "0      Bukan  \n",
       "1      Bukan  \n",
       "2      Bukan  \n",
       "3         Ya  \n",
       "4      Bukan  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert chunks to a pandas DataFrame\n",
    "df = pd.DataFrame(chunks)\n",
    "\n",
    "# Show Data Before Saving\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('konsolidasi_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Koneksi ke server MongoDB\n",
    "# client = MongoClient('localhost', 27017)\n",
    "\n",
    "# # Pilih database\n",
    "# db = client['inatax']\n",
    "\n",
    "# # Pilih koleksi\n",
    "# collection = db['de']\n",
    "\n",
    "# # Baca data dari file CSV\n",
    "# csv_file_path = './konsolidasi_data.csv'\n",
    "# data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Konversi DataFrame ke format JSON (dict)\n",
    "# data_dict = data.to_dict(orient='records')\n",
    "\n",
    "# # Simpan data ke dalam koleksi MongoDB\n",
    "# collection.insert_many(data_dict)\n",
    "\n",
    "# print(\"Data berhasil disimpan ke MongoDB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
